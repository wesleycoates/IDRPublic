{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Model Building\n",
    "\n",
    "This notebook guides you through the process of exploring your data and building a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, let's import the necessary libraries and load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "from typing import Optional, List, Dict, Any, Tuple\n",
      "import pickle\n",
      "from pathlib import Path\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
      "from sklearn.metrics import (\n",
      "    mean_squared_error, mean_absolute_error, r2_score,  # Regression metrics\n",
      "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix,  # Classification metrics\n",
      "    roc_auc_score, roc_curve, precision_recall_curve\n",
      ")\n",
      "\n",
      "# Import various models\n",
      "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
      "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
      "from sklearn.svm import SVR, SVC\n",
      "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
      "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
      "\n",
      "\n",
      "def get_numeric_and_categorical_columns(df: pd.DataFrame) -> Tuple[List[str], List[str]]:\n",
      "    \"\"\"\n",
      "    Identify numeric and categorical columns in a DataFrame.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    df : pd.DataFrame\n",
      "        The data to analyze\n",
      "        \n",
      "    Returns:\n",
      "    --------\n",
      "    tuple\n",
      "        Lists of numeric and categorical column names\n",
      "    \"\"\"\n",
      "    # Identify numeric columns (excluding any obvious target/ID columns)\n",
      "    numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
      "    \n",
      "    # Identify categorical columns - including object, category and boolean types\n",
      "    categorical_columns = df.select_dtypes(include=['object', 'category', 'bool']).columns.tolist()\n",
      "    \n",
      "    return numeric_columns, categorical_columns\n",
      "\n",
      "\n",
      "def create_preprocessing_pipeline(numeric_columns: List[str], categorical_columns: List[str]) -> ColumnTransformer:\n",
      "    \"\"\"\n",
      "    Create a preprocessing pipeline for numeric and categorical features.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    numeric_columns : list of str\n",
      "        Names of numeric columns\n",
      "    categorical_columns : list of str\n",
      "        Names of categorical columns\n",
      "        \n",
      "    Returns:\n",
      "    --------\n",
      "    ColumnTransformer\n",
      "        Preprocessing pipeline\n",
      "    \"\"\"\n",
      "    # Define numeric preprocessing pipeline\n",
      "    numeric_transformer = Pipeline(steps=[\n",
      "        ('imputer', SimpleImputer(strategy='median')),\n",
      "        ('scaler', StandardScaler())\n",
      "    ])\n",
      "    \n",
      "    # Define categorical preprocessing pipeline\n",
      "    categorical_transformer = Pipeline(steps=[\n",
      "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
      "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
      "    ])\n",
      "    \n",
      "    # Combine preprocessing steps\n",
      "    preprocessor = ColumnTransformer(\n",
      "        transformers=[\n",
      "            ('num', numeric_transformer, numeric_columns),\n",
      "            ('cat', categorical_transformer, categorical_columns)\n",
      "        ]\n",
      "    )\n",
      "    \n",
      "    return preprocessor\n",
      "\n",
      "\n",
      "def get_regression_models() -> Dict[str, Any]:\n",
      "    \"\"\"\n",
      "    Get a dictionary of regression models.\n",
      "    \n",
      "    Returns:\n",
      "    --------\n",
      "    dict\n",
      "        Dictionary with model names as keys and model instances as values\n",
      "    \"\"\"\n",
      "    return {\n",
      "        'Linear Regression': LinearRegression(),\n",
      "        'Ridge Regression': Ridge(),\n",
      "        'Lasso Regression': Lasso(),\n",
      "        'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
      "        'Random Forest': RandomForestRegressor(random_state=42),\n",
      "        'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
      "        'SVR': SVR(),\n",
      "        'KNN': KNeighborsRegressor()\n",
      "    }\n",
      "\n",
      "\n",
      "def get_classification_models() -> Dict[str, Any]:\n",
      "    \"\"\"\n",
      "    Get a dictionary of classification models.\n",
      "    \n",
      "    Returns:\n",
      "    --------\n",
      "    dict\n",
      "        Dictionary with model names as keys and model instances as values\n",
      "    \"\"\"\n",
      "    return {\n",
      "        'Logistic Regression': LogisticRegression(random_state=42),\n",
      "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
      "        'Random Forest': RandomForestClassifier(random_state=42),\n",
      "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
      "        'SVC': SVC(probability=True, random_state=42),\n",
      "        'KNN': KNeighborsClassifier()\n",
      "    }\n",
      "\n",
      "\n",
      "def evaluate_regression_models(X_train: pd.DataFrame, y_train: pd.Series, \n",
      "                              X_test: pd.DataFrame, y_test: pd.Series,\n",
      "                              preprocessor: ColumnTransformer) -> pd.DataFrame:\n",
      "    \"\"\"\n",
      "    Evaluate multiple regression models and return their performance metrics.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    X_train : pd.DataFrame\n",
      "        Training features\n",
      "    y_train : pd.Series\n",
      "        Training target\n",
      "    X_test : pd.DataFrame\n",
      "        Testing features\n",
      "    y_test : pd.Series\n",
      "        Testing target\n",
      "    preprocessor : ColumnTransformer\n",
      "        Preprocessing pipeline\n",
      "        \n",
      "    Returns:\n",
      "    --------\n",
      "    pd.DataFrame\n",
      "        Performance metrics for each model\n",
      "    \"\"\"\n",
      "    # Get regression models\n",
      "    models = get_regression_models()\n",
      "    \n",
      "    # Results dictionary\n",
      "    results = []\n",
      "    \n",
      "    for name, model in models.items():\n",
      "        # Create pipeline with preprocessor and model\n",
      "        pipeline = Pipeline(steps=[\n",
      "            ('preprocessor', preprocessor),\n",
      "            ('model', model)\n",
      "        ])\n",
      "        \n",
      "        # Fit model\n",
      "        pipeline.fit(X_train, y_train)\n",
      "        \n",
      "        # Make predictions\n",
      "        y_pred = pipeline.predict(X_test)\n",
      "        \n",
      "        # Calculate metrics\n",
      "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
      "        mae = mean_absolute_error(y_test, y_pred)\n",
      "        r2 = r2_score(y_test, y_pred)\n",
      "        \n",
      "        # Calculate cross-validation score\n",
      "        cv_score = np.mean(cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2'))\n",
      "        \n",
      "        # Store results\n",
      "        results.append({\n",
      "            'Model': name,\n",
      "            'RMSE': rmse,\n",
      "            'MAE': mae,\n",
      "            'R²': r2,\n",
      "            'CV R²': cv_score\n",
      "        })\n",
      "    \n",
      "    # Convert to DataFrame and sort by R²\n",
      "    results_df = pd.DataFrame(results)\n",
      "    results_df = results_df.sort_values('R²', ascending=False).reset_index(drop=True)\n",
      "    \n",
      "    return results_df\n",
      "\n",
      "\n",
      "def evaluate_classification_models(X_train: pd.DataFrame, y_train: pd.Series, \n",
      "                                  X_test: pd.DataFrame, y_test: pd.Series,\n",
      "                                  preprocessor: ColumnTransformer) -> pd.DataFrame:\n",
      "    \"\"\"\n",
      "    Evaluate multiple classification models and return their performance metrics.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    X_train : pd.DataFrame\n",
      "        Training features\n",
      "    y_train : pd.Series\n",
      "        Training target\n",
      "    X_test : pd.DataFrame\n",
      "        Testing features\n",
      "    y_test : pd.Series\n",
      "        Testing target\n",
      "    preprocessor : ColumnTransformer\n",
      "        Preprocessing pipeline\n",
      "        \n",
      "    Returns:\n",
      "    --------\n",
      "    pd.DataFrame\n",
      "        Performance metrics for each model\n",
      "    \"\"\"\n",
      "    # Get classification models\n",
      "    models = get_classification_models()\n",
      "    \n",
      "    # Results dictionary\n",
      "    results = []\n",
      "    \n",
      "    for name, model in models.items():\n",
      "        # Create pipeline with preprocessor and model\n",
      "        pipeline = Pipeline(steps=[\n",
      "            ('preprocessor', preprocessor),\n",
      "            ('model', model)\n",
      "        ])\n",
      "        \n",
      "        # Fit model\n",
      "        pipeline.fit(X_train, y_train)\n",
      "        \n",
      "        # Make predictions\n",
      "        y_pred = pipeline.predict(X_test)\n",
      "        \n",
      "        # For ROC-AUC, we need probability predictions\n",
      "        try:\n",
      "            y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
      "            roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
      "        except:\n",
      "            roc_auc = np.nan\n",
      "        \n",
      "        # Calculate metrics\n",
      "        accuracy = accuracy_score(y_test, y_pred)\n",
      "        \n",
      "        # For multi-class problems, we need to specify an average method\n",
      "        if len(np.unique(y_train)) > 2:\n",
      "            precision = precision_score(y_test, y_pred, average='weighted')\n",
      "            recall = recall_score(y_test, y_pred, average='weighted')\n",
      "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
      "        else:\n",
      "            precision = precision_score(y_test, y_pred)\n",
      "            recall = recall_score(y_test, y_pred)\n",
      "            f1 = f1_score(y_test, y_pred)\n",
      "        \n",
      "        # Calculate cross-validation score\n",
      "        cv_score = np.mean(cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy'))\n",
      "        \n",
      "        # Store results\n",
      "        results.append({\n",
      "            'Model': name,\n",
      "            'Accuracy': accuracy,\n",
      "            'Precision': precision,\n",
      "            'Recall': recall,\n",
      "            'F1 Score': f1,\n",
      "            'ROC-AUC': roc_auc,\n",
      "            'CV Accuracy': cv_score\n",
      "        })\n",
      "    \n",
      "    # Convert to DataFrame and sort by F1 Score\n",
      "    results_df = pd.DataFrame(results)\n",
      "    results_df = results_df.sort_values('F1 Score', ascending=False).reset_index(drop=True)\n",
      "    \n",
      "    return results_df\n",
      "\n",
      "\n",
      "def tune_hyperparameters(X_train: pd.DataFrame, y_train: pd.Series,\n",
      "                        model, param_grid: Dict[str, Any],\n",
      "                        preprocessor: ColumnTransformer,\n",
      "                        cv: int = 5, scoring: str = None):\n",
      "    \"\"\"\n",
      "    Tune hyperparameters for a given model using GridSearchCV.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    X_train : pd.DataFrame\n",
      "        Training features\n",
      "    y_train : pd.Series\n",
      "        Training target\n",
      "    model : estimator\n",
      "        The model to tune\n",
      "    param_grid : dict\n",
      "        Parameter grid for hyperparameter tuning\n",
      "    preprocessor : ColumnTransformer\n",
      "        Preprocessing pipeline\n",
      "    cv : int, default=5\n",
      "        Number of cross-validation folds\n",
      "    scoring : str, optional\n",
      "        Scoring metric to use\n",
      "        \n",
      "    Returns:\n",
      "    --------\n",
      "    tuple\n",
      "        Best estimator and a DataFrame with detailed CV results\n",
      "    \"\"\"\n",
      "    # Create pipeline with preprocessor and model\n",
      "    pipeline = Pipeline(steps=[\n",
      "        ('preprocessor', preprocessor),\n",
      "        ('model', model)\n",
      "    ])\n",
      "    \n",
      "    # Create parameter grid for the pipeline\n",
      "    pipeline_param_grid = {f'model__{param}': values for param, values in param_grid.items()}\n",
      "    \n",
      "    # Create grid search\n",
      "    grid_search = GridSearchCV(\n",
      "        pipeline,\n",
      "        param_grid=pipeline_param_grid,\n",
      "        cv=cv,\n",
      "        scoring=scoring,\n",
      "        n_jobs=-1,\n",
      "        verbose=1\n",
      "    )\n",
      "    \n",
      "    # Fit grid search\n",
      "    grid_search.fit(X_train, y_train)\n",
      "    \n",
      "    # Convert CV results to DataFrame\n",
      "    cv_results = pd.DataFrame(grid_search.cv_results_)\n",
      "    \n",
      "    # Get only relevant columns\n",
      "    cv_results = cv_results[[col for col in cv_results.columns if 'param_' in col or 'mean_test_score' in col or 'std_test_score' in col]]\n",
      "    \n",
      "    # Rename parameter columns\n",
      "    cv_results.columns = [col.replace('param_model__', '') if 'param_model__' in col else col for col in cv_results.columns]\n",
      "    \n",
      "    # Sort by mean test score\n",
      "    cv_results = cv_results.sort_values('mean_test_score', ascending=False).reset_index(drop=True)\n",
      "    \n",
      "    return grid_search.best_estimator_, cv_results\n",
      "\n",
      "\n",
      "def save_model(model, filepath: str):\n",
      "    \"\"\"\n",
      "    Save a trained model to disk.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    model : estimator\n",
      "        Trained model to save\n",
      "    filepath : str\n",
      "        Path where the model will be saved\n",
      "    \"\"\"\n",
      "    # Create directory if it doesn't exist\n",
      "    Path(filepath).parent.mkdir(parents=True, exist_ok=True)\n",
      "    \n",
      "    # Save model\n",
      "    with open(filepath, 'wb') as f:\n",
      "        pickle.dump(model, f)\n",
      "    \n",
      "    print(f\"Model saved to {filepath}\")\n",
      "\n",
      "\n",
      "def load_model(filepath: str):\n",
      "    \"\"\"\n",
      "    Load a trained model from disk.\n",
      "    \n",
      "    Parameters:\n",
      "    -----------\n",
      "    filepath : str\n",
      "        Path where the model is saved\n",
      "        \n",
      "    Returns:\n",
      "    --------\n",
      "    The loaded model\n",
      "    \"\"\"\n",
      "    with open(filepath, 'rb') as f:\n",
      "        model = pickle.load(f)\n",
      "    \n",
      "    print(f\"Model loaded from {filepath}\")\n",
      "    return model\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    # This will execute when you run this script directly\n",
      "    print(\"This is a module for building and evaluating predictive models.\")\n",
      "    print(\"Example usage:\")\n",
      "    print(\"from modeling import evaluate_regression_models, evaluate_classification_models\")\n",
      "    print(\"results = evaluate_regression_models(X_train, y_train, X_test, y_test, preprocessor)\")\n"
     ]
    }
   ],
   "source": [
    "# To inspect the file\n",
    "with open('../src/modeling.py', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for modeling.py at: /workspaces/IDRPublic/src/modeling.py\n",
      "File exists: True\n",
      "First few lines of the file:\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from typing import Optional, List, Dict, Any, Tuple\n",
      "import pickle\n",
      "from pathlib import Path\n",
      "\n",
      "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
      "from sklearn.compose import ColumnTransformer\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
      "from sklearn.metrics import (\n",
      "    mean_squared_error, mean_absolute_error, r2_score,  # Regression metrics\n",
      "    acc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check the exact path being used\n",
    "expected_path = os.path.abspath(os.path.join('..', 'src', 'modeling.py'))\n",
    "print(f\"Looking for modeling.py at: {expected_path}\")\n",
    "print(f\"File exists: {os.path.exists(expected_path)}\")\n",
    "\n",
    "# Read the first few lines to confirm it's the correct file\n",
    "if os.path.exists(expected_path):\n",
    "    with open(expected_path, 'r') as f:\n",
    "        content = f.read(500)  # Read first 500 characters\n",
    "        print(\"First few lines of the file:\")\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function exists in direct import: True\n",
      "Function signature: {'df': <class 'pandas.core.frame.DataFrame'>, 'return': typing.Tuple[typing.List[str], typing.List[str]]}\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Load the module directly from the file path\n",
    "expected_path = '/workspaces/IDRPublic/src/modeling.py'\n",
    "spec = importlib.util.spec_from_file_location(\"modeling_direct\", expected_path)\n",
    "modeling_direct = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"modeling_direct\"] = modeling_direct\n",
    "spec.loader.exec_module(modeling_direct)\n",
    "\n",
    "# Check if the function exists in the loaded module\n",
    "print(\"Function exists in direct import:\", hasattr(modeling_direct, \"get_numeric_and_categorical_columns\"))\n",
    "\n",
    "# Try to access the function\n",
    "if hasattr(modeling_direct, \"get_numeric_and_categorical_columns\"):\n",
    "    print(\"Function signature:\", modeling_direct.get_numeric_and_categorical_columns.__annotations__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed functions directly from our manually loaded module\n",
    "get_numeric_and_categorical_columns = modeling_direct.get_numeric_and_categorical_columns\n",
    "create_preprocessing_pipeline = modeling_direct.create_preprocessing_pipeline\n",
    "evaluate_regression_models = modeling_direct.evaluate_regression_models\n",
    "evaluate_classification_models = modeling_direct.evaluate_classification_models\n",
    "\n",
    "# Test that the function works\n",
    "import pandas as pd\n",
    "test_df = pd.DataFrame({'A': [1, 2, 3], 'B': ['x', 'y', 'z']})\n",
    "num_cols, cat_cols = get_numeric_and_categorical_columns(test_df)\n",
    "print(\"Numeric columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "\n",
    "# Import custom modules (adjust the path if needed)\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_loader import load_excel_data, clean_data, split_data\n",
    "from visualization import plot_numeric_distribution, plot_correlation_matrix, plot_feature_importance\n",
    "from modeling import (get_numeric_and_categorical_columns, create_preprocessing_pipeline,\n",
    "                      evaluate_regression_models, evaluate_classification_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded sheet: OON Emergency and Non-Emergency\n",
      "Shape of dataframe: (65271, 30)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dispute Number</th>\n",
       "      <th>DLI Number</th>\n",
       "      <th>Payment Determination Outcome</th>\n",
       "      <th>Default Decision</th>\n",
       "      <th>Type of Dispute</th>\n",
       "      <th>Provider/Facility Group Name</th>\n",
       "      <th>Provider/Facility Name</th>\n",
       "      <th>Provider Email Domain</th>\n",
       "      <th>Provider/Facility NPI Number</th>\n",
       "      <th>Practice/Facility Size</th>\n",
       "      <th>...</th>\n",
       "      <th>Location of Service</th>\n",
       "      <th>Practice/Facility Specialty or Type</th>\n",
       "      <th>Provider/Facility Offer as Percent of QPA</th>\n",
       "      <th>Health Plan/Issuer Offer as Percent of QPA</th>\n",
       "      <th>Offer Selected from Provider or Issuer</th>\n",
       "      <th>Prevailing Party Offer as Percent of QPA</th>\n",
       "      <th>QPA as Percent of Median QPA</th>\n",
       "      <th>Provider/Facility Offer as Percent of Median Provider/Facility Offer Amount</th>\n",
       "      <th>Health Plan/Issuer Offer as Percent of Median Health Plan/Issuer Offer Amount</th>\n",
       "      <th>Prevailing Offer as Percent of Median Prevailing Offer Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DISP-135724</td>\n",
       "      <td>DLI - 582653</td>\n",
       "      <td>In Favor of Plan/Issuer</td>\n",
       "      <td>No</td>\n",
       "      <td>Single</td>\n",
       "      <td>LONGHORN EMERGENCY MEDICAL ASSOCIATES PA</td>\n",
       "      <td>BLUDWORTH MD,WHITNEY G</td>\n",
       "      <td>teamhealth.com</td>\n",
       "      <td>1649669672</td>\n",
       "      <td>101-500 Employees</td>\n",
       "      <td>...</td>\n",
       "      <td>TX</td>\n",
       "      <td>EMERGENCY MEDICINE</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1</td>\n",
       "      <td>In Favor of Plan/Issuer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISP-135637</td>\n",
       "      <td>DLI - 582530</td>\n",
       "      <td>In Favor of Plan/Issuer</td>\n",
       "      <td>No</td>\n",
       "      <td>Single</td>\n",
       "      <td>NR</td>\n",
       "      <td>ROXBOROUGH MEMORIAL HOSPITAL</td>\n",
       "      <td>primehealthcare.com</td>\n",
       "      <td>NR</td>\n",
       "      <td>Over 500 Employees</td>\n",
       "      <td>...</td>\n",
       "      <td>PA</td>\n",
       "      <td>ACUTE CARE HOSPITAL</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.7</td>\n",
       "      <td>In Favor of Plan/Issuer</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DISP-135495</td>\n",
       "      <td>DLI - 582345</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>No</td>\n",
       "      <td>Single</td>\n",
       "      <td>WOODLANDS EMERGENCY PHYSICIANS</td>\n",
       "      <td>WOODLANDS EMERGENCY PHYSICIANS</td>\n",
       "      <td>r1rcm.com</td>\n",
       "      <td>1467989871</td>\n",
       "      <td>51-100 Employees</td>\n",
       "      <td>...</td>\n",
       "      <td>TX</td>\n",
       "      <td>Emergency Provider</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1.15</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DISP-135654</td>\n",
       "      <td>DLI - 582547</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>No</td>\n",
       "      <td>Single</td>\n",
       "      <td>APP OF TENNESSEE ED PLLC</td>\n",
       "      <td>APP OF TENNESSEE ED PLLC</td>\n",
       "      <td>r1rcm.com</td>\n",
       "      <td>1003230236</td>\n",
       "      <td>101-500 Employees</td>\n",
       "      <td>...</td>\n",
       "      <td>TN</td>\n",
       "      <td>EmergencyMedicine</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1.15</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DISP-135828</td>\n",
       "      <td>DLI - 582852</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>No</td>\n",
       "      <td>Batched</td>\n",
       "      <td>Remote Neuromonitoring Physicians PC</td>\n",
       "      <td>Remote Neuromonitoring Physicians PC</td>\n",
       "      <td>specialtycare.net</td>\n",
       "      <td>1124253075</td>\n",
       "      <td>Over 500 Employees</td>\n",
       "      <td>...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Intraoperative Neuromonitoring</td>\n",
       "      <td>11.04</td>\n",
       "      <td>0</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>11.04</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>*</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dispute Number    DLI Number              Payment Determination Outcome  \\\n",
       "0    DISP-135724  DLI - 582653                    In Favor of Plan/Issuer   \n",
       "1    DISP-135637  DLI - 582530                    In Favor of Plan/Issuer   \n",
       "2    DISP-135495  DLI - 582345  In Favor of Provider/Facility/AA Provider   \n",
       "3    DISP-135654  DLI - 582547  In Favor of Provider/Facility/AA Provider   \n",
       "4    DISP-135828  DLI - 582852  In Favor of Provider/Facility/AA Provider   \n",
       "\n",
       "  Default Decision Type of Dispute              Provider/Facility Group Name  \\\n",
       "0               No          Single  LONGHORN EMERGENCY MEDICAL ASSOCIATES PA   \n",
       "1               No          Single                                        NR   \n",
       "2               No          Single            WOODLANDS EMERGENCY PHYSICIANS   \n",
       "3               No          Single                  APP OF TENNESSEE ED PLLC   \n",
       "4               No         Batched      Remote Neuromonitoring Physicians PC   \n",
       "\n",
       "                 Provider/Facility Name Provider Email Domain  \\\n",
       "0                BLUDWORTH MD,WHITNEY G        teamhealth.com   \n",
       "1          ROXBOROUGH MEMORIAL HOSPITAL   primehealthcare.com   \n",
       "2        WOODLANDS EMERGENCY PHYSICIANS             r1rcm.com   \n",
       "3              APP OF TENNESSEE ED PLLC             r1rcm.com   \n",
       "4  Remote Neuromonitoring Physicians PC     specialtycare.net   \n",
       "\n",
       "  Provider/Facility NPI Number Practice/Facility Size  ...  \\\n",
       "0                   1649669672      101-500 Employees  ...   \n",
       "1                           NR     Over 500 Employees  ...   \n",
       "2                   1467989871       51-100 Employees  ...   \n",
       "3                   1003230236      101-500 Employees  ...   \n",
       "4                   1124253075     Over 500 Employees  ...   \n",
       "\n",
       "  Location of Service Practice/Facility Specialty or Type  \\\n",
       "0                  TX                  EMERGENCY MEDICINE   \n",
       "1                  PA                 ACUTE CARE HOSPITAL   \n",
       "2                  TX                  Emergency Provider   \n",
       "3                  TN                   EmergencyMedicine   \n",
       "4                  PA      Intraoperative Neuromonitoring   \n",
       "\n",
       "  Provider/Facility Offer as Percent of QPA  \\\n",
       "0                                      1.64   \n",
       "1                                      5.13   \n",
       "2                                      3.19   \n",
       "3                                      2.47   \n",
       "4                                     11.04   \n",
       "\n",
       "   Health Plan/Issuer Offer as Percent of QPA  \\\n",
       "0                                           1   \n",
       "1                                         0.7   \n",
       "2                                        1.15   \n",
       "3                                        1.15   \n",
       "4                                           0   \n",
       "\n",
       "      Offer Selected from Provider or Issuer  \\\n",
       "0                    In Favor of Plan/Issuer   \n",
       "1                    In Favor of Plan/Issuer   \n",
       "2  In Favor of Provider/Facility/AA Provider   \n",
       "3  In Favor of Provider/Facility/AA Provider   \n",
       "4  In Favor of Provider/Facility/AA Provider   \n",
       "\n",
       "  Prevailing Party Offer as Percent of QPA QPA as Percent of Median QPA  \\\n",
       "0                                        1                            1   \n",
       "1                                      0.7                            1   \n",
       "2                                     3.19                         0.27   \n",
       "3                                     2.47                         0.96   \n",
       "4                                    11.04                         0.95   \n",
       "\n",
       "  Provider/Facility Offer as Percent of Median Provider/Facility Offer Amount  \\\n",
       "0                                               0.99                            \n",
       "1                                                  1                            \n",
       "2                                               0.83                            \n",
       "3                                               0.71                            \n",
       "4                                                  1                            \n",
       "\n",
       "   Health Plan/Issuer Offer as Percent of Median Health Plan/Issuer Offer Amount  \\\n",
       "0                                                  1                               \n",
       "1                                                  1                               \n",
       "2                                               0.92                               \n",
       "3                                               1.15                               \n",
       "4                                                  *                               \n",
       "\n",
       "  Prevailing Offer as Percent of Median Prevailing Offer Amount  \n",
       "0                                                  1             \n",
       "1                                                  1             \n",
       "2                                               0.88             \n",
       "3                                               0.71             \n",
       "4                                                  1             \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Excel file\n",
    "file_path = \"../data/raw/2023-q1-federal-idr-puf.xlsx\"\n",
    "\n",
    "\n",
    "# Reading in the second sheet\n",
    "sheet_name = 'OON Emergency and Non-Emergency'\n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "# Display the first few rows to confirm it worked\n",
    "print(f\"Successfully loaded sheet: {sheet_name}\")\n",
    "print(f\"Shape of dataframe: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded sheet: QPA and Offers\n",
      "Shape of dataframe: (68007, 9)\n",
      "\n",
      "First 5 rows of QPA and Offers data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Service Code</th>\n",
       "      <th>Place of Service Code</th>\n",
       "      <th>Geographical Region</th>\n",
       "      <th>QPA</th>\n",
       "      <th>Provider/Facility Offer</th>\n",
       "      <th>Health Plan/Issuer Offer</th>\n",
       "      <th>Offer Selected from Provider or Issuer</th>\n",
       "      <th>Prevailing Offer</th>\n",
       "      <th>Default Decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0436</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Aberdeen, WA</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>^</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0431</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Aberdeen, WA</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>^</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0431</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Aberdeen, WA</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>^</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0431</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Aberdeen, WA</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>^</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0431</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Aberdeen, WA</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>^</td>\n",
       "      <td>In Favor of Provider/Facility/AA Provider</td>\n",
       "      <td>^</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Service Code  Place of Service Code Geographical Region QPA  \\\n",
       "0        A0436                   42.0        Aberdeen, WA   ^   \n",
       "1        A0431                   42.0        Aberdeen, WA   ^   \n",
       "2        A0431                   42.0        Aberdeen, WA   ^   \n",
       "3        A0431                   42.0        Aberdeen, WA   ^   \n",
       "4        A0431                   42.0        Aberdeen, WA   ^   \n",
       "\n",
       "  Provider/Facility Offer Health Plan/Issuer Offer  \\\n",
       "0                       ^                        ^   \n",
       "1                       ^                        ^   \n",
       "2                       ^                        ^   \n",
       "3                       ^                        ^   \n",
       "4                       ^                        ^   \n",
       "\n",
       "      Offer Selected from Provider or Issuer Prevailing Offer Default Decision  \n",
       "0  In Favor of Provider/Facility/AA Provider                ^               No  \n",
       "1  In Favor of Provider/Facility/AA Provider                ^               No  \n",
       "2  In Favor of Provider/Facility/AA Provider                ^               No  \n",
       "3  In Favor of Provider/Facility/AA Provider                ^               No  \n",
       "4  In Favor of Provider/Facility/AA Provider                ^               No  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the other sheet from the Excel file\n",
    "QPA_sheet = 'QPA and Offers'\n",
    "df_QPA = pd.read_excel('../data/raw/2023-q1-federal-idr-puf.xlsx', sheet_name=QPA_sheet)\n",
    "\n",
    "# Display basic info about this sheet\n",
    "print(f\"Successfully loaded sheet: {QPA_sheet}\")\n",
    "print(f\"Shape of dataframe: {df_QPA.shape}\")\n",
    "print(\"\\nFirst 5 rows of QPA and Offers data:\")\n",
    "df_QPA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing\n",
    "\n",
    "Let's clean the data and perform some basic preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "clean_df = clean_data(df)\n",
    "\n",
    "# Display information about the cleaned data\n",
    "print(\"Data information:\")\n",
    "clean_df.info()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(clean_df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "display(clean_df.isna().sum())\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols, categorical_cols = get_numeric_and_categorical_columns(clean_df)\n",
    "print(f\"\\nNumeric columns: {numeric_cols}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Let's examine a sample of categorical columns if any exist\n",
    "if categorical_cols:\n",
    "    for col in categorical_cols[:3]:  # Show first 3 at most\n",
    "        print(f\"\\nUnique values in {col}:\")\n",
    "        display(clean_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization\n",
    "\n",
    "Let's visualize the data to understand it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of numeric features\n",
    "if numeric_cols:\n",
    "    print(\"Distribution of numeric features:\")\n",
    "    plot_numeric_distribution(clean_df, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "if len(numeric_cols) > 1:\n",
    "    print(\"Correlation matrix:\")\n",
    "    plot_correlation_matrix(clean_df, numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Selecting Target Variable\n",
    "\n",
    "Now, let's select the target variable for our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all columns for user to select as target\n",
    "print(\"Available columns for target variable:\")\n",
    "for i, col in enumerate(clean_df.columns):\n",
    "    print(f\"{i}. {col}\")\n",
    "\n",
    "# Select your target variable - change this to your actual target column name\n",
    "target_column = 'your_target_column'  # Replace with the actual column name\n",
    "\n",
    "# Check data type of target variable to determine if this is a regression or classification problem\n",
    "if target_column in clean_df.columns:\n",
    "    print(f\"\\nTarget variable: {target_column}\")\n",
    "    print(f\"Data type: {clean_df[target_column].dtype}\")\n",
    "    \n",
    "    # For numeric target, show distribution\n",
    "    if pd.api.types.is_numeric_dtype(clean_df[target_column]):\n",
    "        print(\"\\nTarget distribution:\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(clean_df[target_column], kde=True)\n",
    "        plt.title(f'Distribution of {target_column}')\n",
    "        plt.show()\n",
    "        \n",
    "        problem_type = 'regression'\n",
    "        print(\"\\nThis appears to be a regression problem.\")\n",
    "    else:\n",
    "        # For categorical target, show value counts\n",
    "        print(\"\\nTarget value counts:\")\n",
    "        display(clean_df[target_column].value_counts())\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(y=clean_df[target_column])\n",
    "        plt.title(f'Count of {target_column}')\n",
    "        plt.show()\n",
    "        \n",
    "        problem_type = 'classification'\n",
    "        print(\"\\nThis appears to be a classification problem.\")\n",
    "else:\n",
    "    print(f\"Error: '{target_column}' not found in the data. Please select a valid column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Splitting\n",
    "\n",
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data - make sure to use your actual target column name\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = split_data(clean_df, target_column)\n",
    "    \n",
    "    print(f\"Training features shape: {X_train.shape}\")\n",
    "    print(f\"Testing features shape: {X_test.shape}\")\n",
    "    print(f\"Training target shape: {y_train.shape}\")\n",
    "    print(f\"Testing target shape: {y_test.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please make sure you've selected a valid target column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Building and Evaluation\n",
    "\n",
    "Build and evaluate predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "numeric_cols, categorical_cols = get_numeric_and_categorical_columns(X_train)\n",
    "preprocessor = create_preprocessing_pipeline(numeric_cols, categorical_cols)\n",
    "\n",
    "# Evaluate models based on problem type\n",
    "if 'problem_type' in locals() and problem_type == 'regression':\n",
    "    # Evaluate regression models\n",
    "    print(\"Evaluating regression models...\")\n",
    "    regression_results = evaluate_regression_models(X_train, y_train, X_test, y_test, preprocessor)\n",
    "    display(regression_results)\n",
    "    \n",
    "    # Plot model comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='R²', y='Model', data=regression_results)\n",
    "    plt.title('Model Comparison - R² Score')\n",
    "    plt.xlim(0, 1)  # R² typically ranges from 0 to 1\n",
    "    plt.show()\n",
    "    \n",
    "elif 'problem_type' in locals() and problem_type == 'classification':\n",
    "    # Evaluate classification models\n",
    "    print(\"Evaluating classification models...\")\n",
    "    classification_results = evaluate_classification_models(X_train, y_train, X_test, y_test, preprocessor)\n",
    "    display(classification_results)\n",
    "    \n",
    "    # Plot model comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='F1 Score', y='Model', data=classification_results)\n",
    "    plt.title('Model Comparison - F1 Score')\n",
    "    plt.xlim(0, 1)  # F1 score ranges from 0 to 1\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Please run the previous cell to determine the problem type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance\n",
    "\n",
    "Let's examine which features are most important for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best model based on problem type\n",
    "if 'problem_type' in locals() and problem_type == 'regression' and 'regression_results' in locals():\n",
    "    best_model_name = regression_results.iloc[0]['Model']\n",
    "    print(f\"Best regression model: {best_model_name}\")\n",
    "    \n",
    "    # For tree-based models, we can extract feature importance\n",
    "    if best_model_name in ['Random Forest', 'Gradient Boosting', 'Decision Tree']:\n",
    "        # Import and get models\n",
    "        from modeling import get_regression_models\n",
    "        models = get_regression_models()\n",
    "        \n",
    "        # Get the best model\n",
    "        best_model = models[best_model_name]\n",
    "        \n",
    "        # Create full pipeline\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "        \n",
    "        # Fit model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = numeric_cols.copy()\n",
    "        # For categorical features, get one-hot encoded column names\n",
    "        for cat_col in categorical_cols:\n",
    "            unique_values = X_train[cat_col].unique()\n",
    "            for value in unique_values:\n",
    "                feature_names.append(f\"{cat_col}_{value}\")\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = pipeline.named_steps['model'].feature_importances_\n",
    "        \n",
    "        # Get the right number of feature names\n",
    "        if len(feature_names) > len(importances):\n",
    "            feature_names = feature_names[:len(importances)]\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plot_feature_importance(feature_names, importances, title=f\"{best_model_name} - Feature Importance\")\n",
    "    \n",
    "elif 'problem_type' in locals() and problem_type == 'classification' and 'classification_results' in locals():\n",
    "    best_model_name = classification_results.iloc[0]['Model']\n",
    "    print(f\"Best classification model: {best_model_name}\")\n",
    "    \n",
    "    # For tree-based models, we can extract feature importance\n",
    "    if best_model_name in ['Random Forest', 'Gradient Boosting', 'Decision Tree']:\n",
    "        # Import and get models\n",
    "        from modeling import get_classification_models\n",
    "        models = get_classification_models()\n",
    "        \n",
    "        # Get the best model\n",
    "        best_model = models[best_model_name]\n",
    "        \n",
    "        # Create full pipeline\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "        \n",
    "        # Fit model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = numeric_cols.copy()\n",
    "        # For categorical features, get one-hot encoded column names\n",
    "        for cat_col in categorical_cols:\n",
    "            unique_values = X_train[cat_col].unique()\n",
    "            for value in unique_values:\n",
    "                feature_names.append(f\"{cat_col}_{value}\")\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = pipeline.named_steps['model'].feature_importances_\n",
    "        \n",
    "        # Get the right number of feature names\n",
    "        if len(feature_names) > len(importances):\n",
    "            feature_names = feature_names[:len(importances)]\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plot_feature_importance(feature_names, importances, title=f\"{best_model_name} - Feature Importance\")\n",
    "else:\n",
    "    print(\"Please run the model evaluation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the Best Model\n",
    "\n",
    "Save the best performing model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "if 'pipeline' in locals():\n",
    "    from modeling import save_model\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    import os\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f'../models/best_{problem_type}_model.pkl'\n",
    "    save_model(pipeline, model_path)\n",
    "    \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "else:\n",
    "    print(\"Please run the model evaluation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "Here are some suggestions for next steps:\n",
    "\n",
    "1. **Feature Engineering**: Create new features or transform existing ones to improve model performance\n",
    "2. **Hyperparameter Tuning**: Fine-tune the best model to improve its performance\n",
    "3. **Model Interpretation**: Use tools like SHAP values to better understand model predictions\n",
    "4. **Cross-Validation**: Perform more robust model evaluation using cross-validation\n",
    "5. **Create a Prediction Pipeline**: Build a reusable pipeline for making predictions on new data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
