{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Model Building\n",
    "\n",
    "This notebook guides you through the process of exploring your data and building a predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "First, let's import the necessary libraries and load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "\n",
    "# Import custom modules (adjust the path if needed)\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from data_loader import load_excel_data, clean_data, split_data\n",
    "from visualization import plot_numeric_distribution, plot_correlation_matrix, plot_feature_importance\n",
    "from modeling import (get_numeric_and_categorical_columns, create_preprocessing_pipeline,\n",
    "                      evaluate_regression_models, evaluate_classification_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load your data - replace with your actual file path\n",
    "file_path = \"../data/raw/your_excel_file.xlsx\"\n",
    "\n",
    "# Try to load the data\n",
    "try:\n",
    "    df = load_excel_data(file_path)\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    display(df.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please make sure the file exists and the path is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preprocessing\n",
    "\n",
    "Let's clean the data and perform some basic preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clean the data\n",
    "clean_df = clean_data(df)\n",
    "\n",
    "# Display information about the cleaned data\n",
    "print(\"Data information:\")\n",
    "clean_df.info()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "display(clean_df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "display(clean_df.isna().sum())\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols, categorical_cols = get_numeric_and_categorical_columns(clean_df)\n",
    "print(f\"\\nNumeric columns: {numeric_cols}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "# Let's examine a sample of categorical columns if any exist\n",
    "if categorical_cols:\n",
    "    for col in categorical_cols[:3]:  # Show first 3 at most\n",
    "        print(f\"\\nUnique values in {col}:\")\n",
    "        display(clean_df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Visualization\n",
    "\n",
    "Let's visualize the data to understand it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Distribution of numeric features\n",
    "if numeric_cols:\n",
    "    print(\"Distribution of numeric features:\")\n",
    "    plot_numeric_distribution(clean_df, numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Correlation matrix\n",
    "if len(numeric_cols) > 1:\n",
    "    print(\"Correlation matrix:\")\n",
    "    plot_correlation_matrix(clean_df, numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Selecting Target Variable\n",
    "\n",
    "Now, let's select the target variable for our predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# List all columns for user to select as target\n",
    "print(\"Available columns for target variable:\")\n",
    "for i, col in enumerate(clean_df.columns):\n",
    "    print(f\"{i}. {col}\")\n",
    "\n",
    "# Select your target variable - change this to your actual target column name\n",
    "target_column = 'your_target_column'  # Replace with the actual column name\n",
    "\n",
    "# Check data type of target variable to determine if this is a regression or classification problem\n",
    "if target_column in clean_df.columns:\n",
    "    print(f\"\\nTarget variable: {target_column}\")\n",
    "    print(f\"Data type: {clean_df[target_column].dtype}\")\n",
    "    \n",
    "    # For numeric target, show distribution\n",
    "    if pd.api.types.is_numeric_dtype(clean_df[target_column]):\n",
    "        print(\"\\nTarget distribution:\")\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(clean_df[target_column], kde=True)\n",
    "        plt.title(f'Distribution of {target_column}')\n",
    "        plt.show()\n",
    "        \n",
    "        problem_type = 'regression'\n",
    "        print(\"\\nThis appears to be a regression problem.\")\n",
    "    else:\n",
    "        # For categorical target, show value counts\n",
    "        print(\"\\nTarget value counts:\")\n",
    "        display(clean_df[target_column].value_counts())\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(y=clean_df[target_column])\n",
    "        plt.title(f'Count of {target_column}')\n",
    "        plt.show()\n",
    "        \n",
    "        problem_type = 'classification'\n",
    "        print(\"\\nThis appears to be a classification problem.\")\n",
    "else:\n",
    "    print(f\"Error: '{target_column}' not found in the data. Please select a valid column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Splitting\n",
    "\n",
    "Split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Split the data - make sure to use your actual target column name\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = split_data(clean_df, target_column)\n",
    "    \n",
    "    print(f\"Training features shape: {X_train.shape}\")\n",
    "    print(f\"Testing features shape: {X_test.shape}\")\n",
    "    print(f\"Training target shape: {y_train.shape}\")\n",
    "    print(f\"Testing target shape: {y_test.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please make sure you've selected a valid target column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Building and Evaluation\n",
    "\n",
    "Build and evaluate predictive models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create preprocessing pipeline\n",
    "numeric_cols, categorical_cols = get_numeric_and_categorical_columns(X_train)\n",
    "preprocessor = create_preprocessing_pipeline(numeric_cols, categorical_cols)\n",
    "\n",
    "# Evaluate models based on problem type\n",
    "if 'problem_type' in locals() and problem_type == 'regression':\n",
    "    # Evaluate regression models\n",
    "    print(\"Evaluating regression models...\")\n",
    "    regression_results = evaluate_regression_models(X_train, y_train, X_test, y_test, preprocessor)\n",
    "    display(regression_results)\n",
    "    \n",
    "    # Plot model comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='R²', y='Model', data=regression_results)\n",
    "    plt.title('Model Comparison - R² Score')\n",
    "    plt.xlim(0, 1)  # R² typically ranges from 0 to 1\n",
    "    plt.show()\n",
    "    \n",
    "elif 'problem_type' in locals() and problem_type == 'classification':\n",
    "    # Evaluate classification models\n",
    "    print(\"Evaluating classification models...\")\n",
    "    classification_results = evaluate_classification_models(X_train, y_train, X_test, y_test, preprocessor)\n",
    "    display(classification_results)\n",
    "    \n",
    "    # Plot model comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x='F1 Score', y='Model', data=classification_results)\n",
    "    plt.title('Model Comparison - F1 Score')\n",
    "    plt.xlim(0, 1)  # F1 score ranges from 0 to 1\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Please run the previous cell to determine the problem type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance\n",
    "\n",
    "Let's examine which features are most important for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select the best model based on problem type\n",
    "if 'problem_type' in locals() and problem_type == 'regression' and 'regression_results' in locals():\n",
    "    best_model_name = regression_results.iloc[0]['Model']\n",
    "    print(f\"Best regression model: {best_model_name}\")\n",
    "    \n",
    "    # For tree-based models, we can extract feature importance\n",
    "    if best_model_name in ['Random Forest', 'Gradient Boosting', 'Decision Tree']:\n",
    "        # Import and get models\n",
    "        from modeling import get_regression_models\n",
    "        models = get_regression_models()\n",
    "        \n",
    "        # Get the best model\n",
    "        best_model = models[best_model_name]\n",
    "        \n",
    "        # Create full pipeline\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "        \n",
    "        # Fit model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = numeric_cols.copy()\n",
    "        # For categorical features, get one-hot encoded column names\n",
    "        for cat_col in categorical_cols:\n",
    "            unique_values = X_train[cat_col].unique()\n",
    "            for value in unique_values:\n",
    "                feature_names.append(f\"{cat_col}_{value}\")\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = pipeline.named_steps['model'].feature_importances_\n",
    "        \n",
    "        # Get the right number of feature names\n",
    "        if len(feature_names) > len(importances):\n",
    "            feature_names = feature_names[:len(importances)]\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plot_feature_importance(feature_names, importances, title=f\"{best_model_name} - Feature Importance\")\n",
    "    \n",
    "elif 'problem_type' in locals() and problem_type == 'classification' and 'classification_results' in locals():\n",
    "    best_model_name = classification_results.iloc[0]['Model']\n",
    "    print(f\"Best classification model: {best_model_name}\")\n",
    "    \n",
    "    # For tree-based models, we can extract feature importance\n",
    "    if best_model_name in ['Random Forest', 'Gradient Boosting', 'Decision Tree']:\n",
    "        # Import and get models\n",
    "        from modeling import get_classification_models\n",
    "        models = get_classification_models()\n",
    "        \n",
    "        # Get the best model\n",
    "        best_model = models[best_model_name]\n",
    "        \n",
    "        # Create full pipeline\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', best_model)])\n",
    "        \n",
    "        # Fit model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = numeric_cols.copy()\n",
    "        # For categorical features, get one-hot encoded column names\n",
    "        for cat_col in categorical_cols:\n",
    "            unique_values = X_train[cat_col].unique()\n",
    "            for value in unique_values:\n",
    "                feature_names.append(f\"{cat_col}_{value}\")\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = pipeline.named_steps['model'].feature_importances_\n",
    "        \n",
    "        # Get the right number of feature names\n",
    "        if len(feature_names) > len(importances):\n",
    "            feature_names = feature_names[:len(importances)]\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plot_feature_importance(feature_names, importances, title=f\"{best_model_name} - Feature Importance\")\n",
    "else:\n",
    "    print(\"Please run the model evaluation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save the Best Model\n",
    "\n",
    "Save the best performing model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the best model\n",
    "if 'pipeline' in locals():\n",
    "    from modeling import save_model\n",
    "    \n",
    "    # Create models directory if it doesn't exist\n",
    "    import os\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f'../models/best_{problem_type}_model.pkl'\n",
    "    save_model(pipeline, model_path)\n",
    "    \n",
    "    print(f\"Model saved to {model_path}\")\n",
    "else:\n",
    "    print(\"Please run the model evaluation first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps\n",
    "\n",
    "Here are some suggestions for next steps:\n",
    "\n",
    "1. **Feature Engineering**: Create new features or transform existing ones to improve model performance\n",
    "2. **Hyperparameter Tuning**: Fine-tune the best model to improve its performance\n",
    "3. **Model Interpretation**: Use tools like SHAP values to better understand model predictions\n",
    "4. **Cross-Validation**: Perform more robust model evaluation using cross-validation\n",
    "5. **Create a Prediction Pipeline**: Build a reusable pipeline for making predictions on new data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}